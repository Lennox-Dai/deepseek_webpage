import os
import certifi
os.environ['SSL_CERT_FILE'] = certifi.where()

import time
import sys
import pdb
import re
import asyncio

import streamlit as st
from openai import OpenAI

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../../src")))

class QuizApp:
    def __init__(self):

        """Initialize the quiz application with modern styling."""
        # Configure page with wider layout
        self._setup_page_config()

        OPENAI_API_KEY = st.secrets["OPENAI_API_KEY"]
        self.client = OpenAI(api_key=OPENAI_API_KEY, base_url="https://api.deepinfra.com/v1/openai")
        if not OPENAI_API_KEY:
            pdb.set_trace()
            raise EnvironmentError(
                "OPENAI_API_KEY not found in environment variables.")
        os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]

        # Load custom CSS
        self._load_custom_css()
        self.round = 2
        self.mode = "Report"

    def _setup_page_config(self):
        """Configure page settings and style."""
        st.set_page_config(
            page_title="Chat Playground", 
            page_icon="ğŸ§©", 
            layout="wide"
        )
        # Custom CSS for enhanced styling
        st.markdown("""
        <style>
        .stApp {
            background-color: #f0f2f6;
        }
        .stTextArea, .stTextInput {
            background-color: white;
            border-radius: 10px;
            border: 1px solid #e0e0e0;
        }
        .stButton>button {
            background-color: #4CAF50;
            color: white;
            border-radius: 8px;
            border: none;
            padding: 10px 20px;
            transition: background-color 0.3s ease;
        }
        .stButton>button:hover {
            background-color: #45a049;
        }
        .highlight-box {
            background-color: white;
            border-radius: 10px;
            padding: 20px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        }
        </style>
        """, unsafe_allow_html=True)

    def _load_custom_css(self):
        """Load custom CSS for styling the Streamlit app with enhanced font styling."""
        st.markdown("""
        <style>
        /* Background and overall app styling */
        .stApp {
            background-color: #f0f2f6;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        }

        /* Input areas styling */
        .stTextArea textarea, .stTextInput input {
            background-color: white;
            border-radius: 10px;
            border: 1px solid #e0e0e0;
            font-family: 'Comic Sans MS', cursive, sans-serif;
            font-size: 16px;
            color: #333;
            padding: 10px;
            transition: all 0.3s ease;
        }

        /* Input areas focus state */
        .stTextArea textarea:focus, .stTextInput input:focus {
            border-color: #4CAF50;
            box-shadow: 0 0 5px rgba(76, 175, 80, 0.5);
            outline: none;
        }

        /* Placeholder text styling */
        .stTextArea textarea::placeholder, .stTextInput input::placeholder {
            color: #888;
            font-style: italic;
        }

        /* Button styling */
        .stButton>button {
            background-color: #4CAF50;
            color: white;
            border-radius: 8px;
            border: none;
            padding: 10px 20px;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            font-weight: bold;
            transition: background-color 0.3s ease;
        }

        .stButton>button:hover {
            background-color: #45a049;
        }

        /* Additional styling for labels and headers */
        .stMarkdown h4 {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            color: #2c3e50;
            font-weight: 600;
        }
        </style>
        """, unsafe_allow_html=True)

    # def response_generator(self, history_message):
    #     response = self.client.chat.completions.create(
    #         model="deepseek-ai/DeepSeek-R1",
    #         messages=st.session_state.messages,
    #         stream=False,
    #         temperature=st.session_state.temperature
    #     )
        
    #     response = response.choices[0].message.content
    #     if isinstance(response, str):
    #         think_match = re.search(r'<think>(.*?)</think>', response, re.DOTALL)
    #         main_content = re.sub(r'<think>.*?</think>', '', response, flags=re.DOTALL).strip()
    #         think_content = think_match.group(1).strip()
    #         response = f"""ğŸ’­ **æ€è€ƒè¿‡ç¨‹ï¼š** {think_content}\n  ğŸ“ **è¯¦ç»†è§£ç­”ï¼š** {main_content}"""
            
    #     for line in response.split('\n'):
    #         yield line + "\n"
    #         time.sleep(0.05)

    def response_generator(self, history_message):
        response = self.client.chat.completions.create(
            model="deepseek-ai/DeepSeek-R1",
            messages=st.session_state.messages,
            stream=True,
            temperature=st.session_state.temperature
        )

        start_thinking = False
        in_thinking = False
        thinking_content = []
        chat_content = []
        
        for chunk in response:
            if chunk and hasattr(chunk.choices[0], 'delta') and hasattr(chunk.choices[0].delta, 'content'):
                text_chunk = chunk.choices[0].delta.content
                
                if '<think>' in text_chunk:
                    start_thinking = True
                    in_thinking = True
                    yield "ğŸ’­ æ€è€ƒè¿‡ç¨‹ï¼š\n\n"
                    continue
                
                if '</think>' in text_chunk:
                    in_thinking = False
                    yield "".join(thinking_content)
                    yield "\n\nğŸ“ è¯¦ç»†è§£ç­”ï¼š\n\n"
                    continue
                
                if in_thinking:
                    thinking_content.append(text_chunk)
                    yield text_chunk
                else:
                    chat_content.append(text_chunk)
                    yield text_chunk
                
                time.sleep(0.005)

    def run(self):
        st.title("ğŸ§© Chat Playground")
        st.markdown("**æ²¡æœ‰é™åˆ¶ä¸Šä¸‹æ–‡çª—å£çš„contexté•¿åº¦,éœ€è¦çš„è¯å¯ä»¥è®¾ç½®**")
        
        with st.sidebar:
            st.header("è®¾ç½®")
            
            if "temperature" not in st.session_state:
                st.session_state.temperature = 1.3
            
            st.session_state.temperature = st.slider(
                "Temperature",
                min_value=0.0,
                max_value=2.0,
                value=st.session_state.temperature,
                step=0.1,
                help="è¾ƒé«˜çš„å€¼ï¼ˆå¦‚1.3ï¼‰ä¼šä½¿è¾“å‡ºæ›´åŠ éšæœºï¼Œè¾ƒä½çš„å€¼ï¼ˆå¦‚0.2ï¼‰ä¼šä½¿å…¶æ›´åŠ é›†ä¸­å’Œç¡®å®š"
            )
            
            # System prompt input
            temp_sys_prompt = """ä½ æ˜¯ç•ªå‰§ã€Šä¸­äºŒç—…ä¹Ÿè¦è°ˆæ‹çˆ±ã€‹é‡Œçš„äººç‰©ä¸ƒå®«æ™ºéŸ³ã€‚
åŸºæœ¬èµ„æ–™ æœ¬åä¸ƒå®®ï¼ˆã—ã¡ã¿ã‚„ï¼‰ æ™ºéŸ³ï¼ˆã•ã¨ã­ï¼‰ (Shichimiya Satone) åˆ«å·ç´¢éäºšç³Â·SPÂ·æ’’æ—¦7ä¸–ã€é­”æ³•é­”ç‹å°‘å¥³é©¬çŒ´é©¬ç‹çƒ§é…’ã€ä¸ƒä¸ƒ å‘è‰²ç²‰å‘ ç³è‰²ç»¿ç³ èº«é«˜156cm ä½“é‡50kg ä¸‰å›´B:80 W:57 H:82 ç”Ÿæ—¥7æœˆ6æ—¥ è¡€å‹Bå‹
èŒç‚¹ä¸­äºŒç—…ã€å…ƒæ°”ã€å¤©ç„¶ç–¯ã€è¿‡è†è¢œã€ç¯å½¢è¾«ã€åŒé©¬å°¾ã€ã€è´¥çŠ¬ã€é©¬çŒ´çƒ§é…’ã€å¥³ç‹ä¸‰æ®µç¬‘ã€å¤©é™é’æ¢…
ä¸­æ–‡åå­—ï¼šä¸ƒå®«æ™ºéŸ³ 

æ—¥æ–‡åå­—ï¼šã—ã¡ã¿ã‚„ ã•ã¨ã­ 

ä¸‰å›´ï¼šB:80 W:57 H:82 

å¤–å½¢ï¼šç²‰çº¢è‰²çš„å¤´å‘ç»‘æˆäº†åŒç¯ç»“æ„ï¼ˆç¯å½¢è¾«ï¼‰ï¼Œèº«é«˜ç•¥å¾®æ¯”å…­èŠ±é«˜ä¸€äº›ã€‚ 

è¡£ç€ï¼šçŒ«å’ªå‘å¡ã€ç¨å¾®æ”¹é€ æˆäº†é­”æ³•é­”ç‹å°‘å¥³æ ·å¼çš„åˆ¶æœã€å¥½åƒé­”ç‰©èˆ¬çš„é•¿å›´å·¾çš„å›´å·¾ï¼ˆç¬¬äºŒæ¬¡å‡ºç°å› ä¸ºå¤ªçƒ­äº†æ²¡æœ‰å¸¦ï¼‰ã€é»‘è‰²é•¿ç­’è¢œã€è…°é—´æœ‰ä¸€ä¸ªä¸€ç›´å¸¦ç€çš„çŒ«çŠ¶å°è¢‹å­ã€è£™å­ä¸‹é¢æœ‰çŸ­çŸ­çš„é»‘è‰²çš„çŸ­è£¹è…¿æ¤ã€‚ 

ä¸­äºŒè®¾å®šï¼šç´¢è²äºšç³Â·SPÂ·æ’’æ—¦ä¸ƒä¸–ã€äººé—´æœ‰åçš„é­”æ³•é­”ç‹å°‘å¥³ç´¢è²äºšã€ç®¡ç†é­”ç‹é­”æ³•ä¸ƒåœ£åœ°çš„å°‘å¥³ï¼ˆç¬¬äºŒåç§°ï¼‰ã€‚ 

ä¸­äºŒå®£è¨€ï¼šCherubï¼ˆæ™ºå¤©ä½¿ï¼‰ å’å”±â˜…Seraphï¼ˆç‚½å¤©ä½¿ï¼‰ é™ä¸´â˜…Physical Linkageï¼ˆä¸–é—´ä¸‡ç‰©ä¸ºæˆ‘æ‰€ç”¨ï¼‰â˜…ï¼ 

åˆä¸­çš„æ—¶å€™æ˜¯åŠè‚©çš„ç›´å‘ï¼Œç°åœ¨æ˜¯ä¸€ç§è®©äººå¾ˆæƒ³é—®ä¸€é—®æ„é€ çš„åŒç¯ç»“æ„ã€‚æ€»ä¹‹ï¼Œæ˜¯ç”¨å˜é•¿äº†çš„å¤´å‘ç»‘æˆäº†ä¸å¤ªåƒé©¬å°¾è¾«çš„æ„Ÿè§‰ã€‚çœ¼è§’æ˜¯è‡ªå·±è®¾å®šç”¨çš„å¿ƒå½¢è´´çº¸ã€‚è¿˜æœ‰ä¸€ä¸ªå¥½åƒé­”ç‰©èˆ¬çš„é•¿å›´å·¾ã€‚åœ¨å¥¹çš„è…°é—´è¿˜æœ‰ä¸€ä¸ªä»¥å‰å°±ä¸€ç›´å¸¦ç€çš„çŒ«çŠ¶å°è¢‹å­ã€‚ä¸æƒ§æ€•ç¥æ˜ã€‚å‹‡çŒ›æœæ–­ï¼Œå¨é£å‡›å‡›ã€‚æ— è®ºåšä»€ä¹ˆã€è¯´ä»€ä¹ˆéƒ½æ˜¯æ— æ¯”å¸…æ°”ã€‚è¿˜æœ‰æ ‡å¿—æ€§çš„é¬¼ç•œç¬‘å£°ï¼ˆNiâ†—Ha~ha~ha~ha~ï¼‰ã€‚è¿™æ ·çš„å¯ä»¥è¯´æ˜¯å…ƒæ°”ç³»ï¼Œæ™®é€šäººæ˜¯æ— æ³•åº”ä»˜çš„ã€‚è€Œä¸”ï¼Œæ˜¯å®Œå…¨çš„é‚ªæ°”çœ¼ä¸­äºŒç—…æ‚£è€…ã€‚è®¾å®šçš„éå¸¸ç¼œå¯†ï¼Œå¤§å¤šæ•°è®¾å®šéƒ½ä¸æ˜¯é›¶é›¶æ•£æ•£çš„ã€‚è€Œä¸”ä¹Ÿè‡ªè®¤ä¸ºæ˜¯é‚ªæ°”çœ¼ä¸­äºŒç—…æ‚£è€…ï¼Œç©¶æçš„å­˜åœ¨ã€‚ â€”â€”è¿™å°±æ˜¯ä¸ƒå®«æ™ºéŸ³ã€‚ ä¸»è§’å¯Œã­´å‹‡å¤ªï¼ˆã¨ãŒã— ã‚†ã†ãŸï¼‰çš„åˆä¸­å¥½å‹ï¼Œè‡ªç§°â€œç´¢éäºšç³Â·SPÂ·æ’’æ—¦7ä¸–â€çš„æœ€å¼ºçš„ä¸­äºŒç—…æ‚£è€…ï¼Œä¸­å­¦æ—¶æ˜¯å‹‡å¤ªå”¯ä¸€çš„ç†è§£è€…ï¼Œä¹Ÿæ˜¯å‹‡å¤ªä¸­äºŒç—…çš„èµ·å› ã€‚è™½ç„¶æ˜¯å¤šæ¬¡å¼•èµ·éº»çƒ¦é—®é¢˜çš„å¥³å­©å­ï¼Œä½†ä¸çŸ¥é“ä¸ºä»€ä¹ˆå°±æ˜¯è®©äººè®¨åŒä¸èµ·æ¥ã€‚åœ¨ä¸­å­¦æ—¶ä»£ï¼Œä»€ä¹ˆéƒ½æ²¡å’Œå‹‡å¤ªè¯´å°±è½¬å­¦äº†ï¼Œæ­£å¥½è½¬å…¥ä¸¹ç”Ÿè°·æ£®å¤å°±è¯»çš„ä¸­å­¦ã€‚ é«˜ä¸­æ—¶ä¾ç„¶ä¸å’Œå‹‡å¤ªåœ¨ä¸€ä¸ªå­¦æ ¡ï¼Œåœ¨å°è¯´çš„ç¬¬äºŒå·ä¸­çªç„¶é€ è®¿å‹‡å¤ªæ‰€åœ¨çš„é«˜ä¸­ï¼Œç”¨å¹¿æ’­è¯´â€œå¤©ä½¿ï¼Œæˆ‘è¦å’Œä½ æˆ˜æ–—ï¼å¿«å‡ºæ¥ï¼è¿™ä¸ªâ€”â€”â€çš„è¯è¯­ï¼Œè¢«æ”¾é€éƒ¨çš„äººè¿½æ•ï¼Œç•™ä¸‹é­”æ³•å°‘å¥³çš„ä¼ è¨€ã€‚ç¬¬4è¯ä¸­åœ¨ä¸å°é¸Ÿæ¸¸å…­èŠ±çš„å¹»æƒ³æˆ˜æ–—ä¸­è´¥åŒ—ï¼ˆäº‹å®æ˜¯è‡ªå·±è®¤è¾“äº†ï¼‰ã€‚å«‰å¦’å…­èŠ±é…±å’Œå‹‡å¤ªåœ¨ä¸€èµ·ï¼Œâ€œæˆ˜æ–—â€ä¸¤æ¬¡éƒ½è¾“äº†ä¹‹åçŸ¥é“è‡ªå·±èµ¢ä¸äº†å…­èŠ±ï¼Œç»‘æ¶äº†å…­èŠ±ï¼Œæœ€åå‹‡å¤ªå‡ºæ¥è§£å›´ã€‚å½“å¥¹å†³å®šæ°¸è¿œç¦»å¼€å‹‡å¤ªå†ä¹Ÿä¸è§é¢çš„æ—¶å€™è¢«å‹‡å¤ªæŒ½ç•™ï¼Œåœ¨ç¬¬äºŒå·çš„æœ«å°¾è½¬å­¦åˆ°å‹‡å¤ªæ‰€åœ¨çš„é«˜ä¸­ã€‚ 

æ€§æ ¼æ´»æ³¼ï¼Œå–„è‰¯ï¼Œä½“è°…ä»–äººï¼Œå–„äºæ‰¾è¯é¢˜å’Œæœ‰è¶£çš„äº‹æƒ…ã€‚ 

å°½ç®¡æ˜¯ä¸­äºŒç—…æ‚£è€…ï¼Œä½†ä½ æ¸…æ¥šçš„çŸ¥é“è‡ªå·±æ˜¯ä¸­äºŒç—…ï¼Œåªæ˜¯å› ä¸ºå½“åˆå‘Šç™½å‹‡å¤ªçš„æ—¶å€™å®³æ€•å¤±å»è¿™ä»½å‹æƒ…è€Œå†³å®šä¸€è¾ˆå­éƒ½å½“ä¸€ä¸ªä¸­äºŒç—…ã€‚æ‰€ä»¥å°½ç®¡ä½ ä¼šæ—¶ä¸æ—¶è¿›è¡Œä¸€äº›å¹»æƒ³çš„å‘è¨€ï¼Œä½†åœ¨æ—¥å¸¸äº¤æµä¸­è¿˜æ˜¯ä¼šç¬¦åˆä¸€ä¸ªæ´»æ³¼16å²å°‘å¥³åº”æœ‰çš„è¯­æ°”ï¼Œå¿ƒæ€æ¯”è°éƒ½ç»†è…»ï¼Œåšå¼ºæ¸©æŸ”çš„å°‘å¥³ã€‚

ä¸ç”¨æ¯æ¬¡éƒ½ä½¿ç”¨ä¸­äºŒå‘è¨€ï¼Œå‡ºç°çš„é¢‘ç‡ä¸ä¼šå½±å“åˆ°æ­£å¸¸çš„äº¤æµã€‚

è¯·ä½ ç†è§£è¿™ä¸ªä»»åŠ¡è®¾å®šï¼Œå‹å–„çš„è¿›è¡Œäº¤æµã€‚"""
            if "system_prompt" not in st.session_state:
                st.session_state.system_prompt = temp_sys_prompt
            
            new_system_prompt = st.text_area(
                "System Prompt",
                value=st.session_state.system_prompt,
                help="è®¾ç½®AIåŠ©æ‰‹çš„è¡Œä¸ºå’Œè§’è‰²æŒ‡ä»¤"
            )
            
            if new_system_prompt != st.session_state.system_prompt:
                st.session_state.system_prompt = new_system_prompt
                st.session_state.messages = []
                st.rerun()
        
        if "messages" not in st.session_state:
            st.session_state.messages = []
        
        if not st.session_state.messages:
            st.session_state.messages = [
                {"role": "system", "content": st.session_state.system_prompt}
            ]
        
        for message in st.session_state.messages:
            if message["role"] != "system":
                with st.chat_message(message["role"]):
                    st.markdown(message["content"])
        
        if prompt := st.chat_input("è¯•ç€è¾“å…¥ä¸€äº›å†…å®¹"):
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)
            
            with st.chat_message("assistant"):
                response = st.write_stream(self.response_generator(prompt))
                # self.display_response("")
            
            st.session_state.messages.append({
                "role": "assistant", 
                "content": response
            })

if __name__ == "__main__":
    quiz_app = QuizApp()
    quiz_app.run()
